{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import mmap\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(path):\n",
    "    Files = []\n",
    "    for path1 in pathlib.Path(path).iterdir():\n",
    "        if path1.is_file():\n",
    "            path1=str(path1)\n",
    "            Files.append(path1)\n",
    "    return Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#function for stemming of terms\n",
    "def apply_stemming(lines):\n",
    "    ps = PorterStemmer()\n",
    "    return ps.stem(lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def doconly(input_doc):\n",
    "    docname=input_doc\n",
    "    #removing exyension\n",
    "    if \".txt\" in input_doc:\n",
    "        \n",
    "        len = len(input_doc)\n",
    "        docname = input_doc[:len-4]\n",
    "        \n",
    "    matched_doc_name =None\n",
    "    matched_doc_id = None\n",
    "    \n",
    "    #directory +'\\\\docids.txt'\n",
    "    with open('docids.txt', 'r', encoding='utf-8', errors='backslashreplace') as file:\n",
    "            while matched_doc_id==None:\n",
    "                row=file.readline()\n",
    "                  \n",
    "                if docname in row:\n",
    "                    \n",
    "                    split_line = row.split('\\t')\n",
    "                    matched_doc_id = int(split_line[0])\n",
    "                    matched_doc_name = str(split_line[1]).split('\\n')[0]\n",
    "                    \n",
    "          \n",
    "    total_terms = 0\n",
    "    unique_terms = 0\n",
    "    \n",
    "    #directory+'\\\\doc_index.txt'\n",
    "    with open('doc_index.txt', 'r', encoding='utf-8', errors='backslashreplace') as file2:\n",
    "        line=file2.readline()\n",
    "        split_line = line.split('\\t')\n",
    "        doc_curr = int(split_line[0])\n",
    "                \n",
    "        while matched_doc_id>=doc_curr:\n",
    "                \n",
    "                line1=file2.readline()\n",
    "                split_line1 = line1.split('\\t')\n",
    "                doc_curr = int(split_line1[0])\n",
    "                if matched_doc_id==doc_curr:\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    term_id = int(split_line1[1])\n",
    "                    frequency = int(split_line1[2])\n",
    "              \n",
    "                    unique_terms += 1 \n",
    "                \n",
    "               \n",
    "                    total_terms += frequency\n",
    "              \n",
    "        print (\"Listing for document: \", matched_doc_name) \n",
    "        print (\"DOCID: \", matched_doc_id) \n",
    "        print (\"Distinct terms: \", unique_terms)\n",
    "        print (\"Total terms: \", total_terms)\n",
    "def termonly(input_term):\n",
    "    stemmed_term = apply_stemming(input_term)\n",
    "    with open('termids.txt', 'r', encoding='utf-8', errors='backslashreplace') as file:\n",
    "        termid=None \n",
    "        term=None\n",
    "        for line in file:\n",
    "            splited_line = line.split('\\t')\n",
    "            if stemmed_term == splited_line[1].split('\\n')[0]:\n",
    "                \n",
    "                termid=(int(splited_line[0]))\n",
    "                term=(splited_line[1].split('\\n')[0])\n",
    "                with open('term_info.txt', 'r', encoding='utf-8', errors='backslashreplace') as file1:\n",
    "                    for line1 in file1:\n",
    "                        splitted_line1 = line1.split('\\t')\n",
    "                        termid1 = int(splitted_line1[0])\n",
    "                        if termid1==termid:\n",
    "                            \n",
    "                            offset = (splitted_line1[1])\n",
    "                            total_frequency = (splitted_line1[2])\n",
    "                            total_document = (splitted_line1[3])\n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "    print('\\n')\n",
    "    print(\"Listing for stemmed term: \", stemmed_term)\n",
    "    print(\"TERMID: \", termid)\n",
    "    print(\"NUMBER  DOCUMENTS CONTANNING TERM: \",total_document)\n",
    "    print(\"TERM FRQ IN CORPUS: \",total_frequency)\n",
    "    print(\"INVERTED LIST OFFSET:\", offset)\n",
    "\n",
    "def specialfilehandling(a):\n",
    "    \n",
    "    fo = open(\"term_index.txt\", \"r\")\n",
    "    line1 = fo.seek(a)\n",
    "\n",
    "    line=fo.readline()\n",
    "\n",
    "    fo.close()\n",
    "    return line\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bothdocumentandterm(docname,termname):\n",
    "    doc_id=None\n",
    "    term_id=None\n",
    "    offset=None\n",
    "    frequency=None\n",
    "    with open('termids.txt', 'r', encoding='utf-8', errors='backslashreplace') as f:\n",
    "        for row in f:\n",
    "            \n",
    "            splitted_row = row.split('\\t')\n",
    "            if termname == str(splitted_row[1]).split('\\n')[0]:\n",
    "                \n",
    "                term_id = int(splitted_row[0])\n",
    "            \n",
    "   \n",
    "    with open('docids.txt', 'r', encoding='utf-8', errors='backslashreplace') as f1:\n",
    "        for row1 in f1:\n",
    "            \n",
    "            splitted_row1 = row1.split('\\t')\n",
    "            if docname == str(splitted_row1[1]).split('\\n')[0]:\n",
    "                \n",
    "                doc_id = int(splitted_row1[0]) \n",
    "                \n",
    "    with open('term_info.txt', 'r', encoding='utf-8', errors='backslashreplace') as f3:\n",
    "        for row3 in f3:\n",
    "            \n",
    "            splitted_row3 = row3.split('\\t')\n",
    "            if term_id == int(splitted_row3[0]):\n",
    "                offset=splitted_row3[1]\n",
    "     \n",
    "    with open('term_index.txt', 'r', encoding='utf-8', errors='backslashreplace') as f4:\n",
    "         \n",
    "            row4=specialfilehandling(int(offset))\n",
    "            splitted_row4 = row4.split('\\t')\n",
    "            for col in splitted_row4:\n",
    "                \n",
    "                if len(col)<2:\n",
    "                    continue\n",
    "                splitted_col1=col.split(':')\n",
    "                 \n",
    "                \n",
    "                if doc_id == int(splitted_col1[0]):\n",
    "                    frequency= int(splitted_col1[1])\n",
    "                    \n",
    "                \n",
    "        \n",
    "    print('\\n')\n",
    "    print(\"Inverted list for term: \", termname )\n",
    "    print(\"In document: \",docname )\n",
    "    print(\"TERMID: \", term_id)\n",
    "    print(\"DOCID: \", doc_id)\n",
    "    print(\"Term frequency in document: \",frequency)\n",
    "            \n",
    "            \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter --term TERM ,--doc DOCNAME ,--term TERM --doc DOCNAME: --term dark\n",
      "\n",
      "\n",
      "Listing for stemmed term:  dark\n",
      "TERMID:  1\n",
      "NUMBER  DOCUMENTS CONTANNING TERM:  562\n",
      "\n",
      "TERM FRQ IN CORPUS:  5830\n",
      "INVERTED LIST OFFSET: 0\n"
     ]
    }
   ],
   "source": [
    "cout = 'Enter --term TERM ,--doc DOCNAME ,--term TERM --doc DOCNAME: '\n",
    "cin = input(cout)\n",
    "\n",
    "\n",
    "splits = cin.split (' ')\n",
    "input_term = None\n",
    "input_doc = None\n",
    "for i in range (len(splits)):\n",
    "    if (splits[i]=='--term'):\n",
    "        \n",
    "        input_term = splits[i+1]\n",
    "    if (splits[i]=='--doc'):\n",
    "        input_doc = splits[i+1]\n",
    "        \n",
    "        \n",
    "#if only term is input\n",
    "if input_term != None and input_doc == None:\n",
    "    termonly(input_term)\n",
    "elif input_term == None and input_doc != None:\n",
    "    doconly(input_doc)\n",
    "elif input_term != None and input_doc != None:\n",
    "    bothdocumentandterm(input_doc,input_term)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'termids.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23088/1862305435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtermonly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dark'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23088/3591570571.py\u001b[0m in \u001b[0;36mtermonly\u001b[1;34m(input_term)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtermonly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mstemmed_term\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_stemming\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'termids.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'backslashreplace'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mtermid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mterm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'termids.txt'"
     ]
    }
   ],
   "source": [
    "termonly('dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout = 'Enter --term TERM ,--doc DOCNAME ,--term TERM --doc DOCNAME: '\n",
    "cin = input(cout)\n",
    "\n",
    "\n",
    "splits = cin.split (' ')\n",
    "input_term = None\n",
    "input_doc = None\n",
    "for i in range (len(splits)):\n",
    "    if (splits[i]=='--term'):\n",
    "        \n",
    "        input_term = splits[i+1]\n",
    "    if (splits[i]=='--doc'):\n",
    "        input_doc = splits[i+1]\n",
    "        \n",
    "        \n",
    "#if only term is input\n",
    "if input_term != None and input_doc == None:\n",
    "    print(str(input_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_23088/301664734.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\maaan\\AppData\\Local\\Temp/ipykernel_23088/301664734.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Enter --term TERM ,--doc DOCNAME ,--term TERM --doc DOCNAME: --term dark --doc clueweb12-0000tw-13-04988\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Enter --term TERM ,--doc DOCNAME ,--term TERM --doc DOCNAME: --term dark --doc clueweb12-0000tw-13-04988  \n",
    "\n",
    "\n",
    "Inverted list for term:  dark\n",
    "In document:  clueweb12-0000tw-13-04988\n",
    "TERMID:  1\n",
    "DOCID:  1\n",
    "Term frequency in document:  8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
